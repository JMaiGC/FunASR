# 基线
## 基线概述
我们将提供一个在[FunASR](https://github.com/alibaba-damo-academy/FunASR)上实现的端到端SA-ASR系统作为基线。该模型的结构如图3所示。SpeakerEncoder用[ModelScope](https://modelscope.cn/home)中预先训练好的[说话人确认模型](https://modelscope.cn/models/damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch/summary)作为初始化。这个说话人确认模型也被用来提取说话人档案中的说话人嵌入。

![model archietecture](images/sa_asr_arch.png)

## 快速开始
#TODO: fill with the README.md of the baseline

## 基线结果
基线系统的结果如表3所示。在训练期间，说话人档案采用了真实说话人嵌入。然而由于在评估过程中缺乏真实说话人标签，因此使用了由额外的谱聚类提供的说话人特征。同时我们还提供了在评估和测试集上使用真实说话人档案的结果，以显示说话人档案准确性的影响。
![baseline result](images/baseline_result.png)